{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Glean CV Approach </h1>\n",
    "We are going to see how we can try Computer Vision Approach to Classify various vendors. The idea is to use EfficientNetB0 to train on the images of first pages of all pdf documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import pprint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Getting Dataset </h3>\n",
    "\n",
    "Initially our files are present as pdf we are going to conver them into images. We are taking the  first page of each pdf file and using it to get the image from that page and going to train only on those  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are vendors: ['../Dataset/ADP_LLC', '../Dataset/Align_Technology_Inc', '../Dataset/ALLIANCE_VANTAGE_LIMITED', '../Dataset/Amazon_Business', '../Dataset/Apple_Inc (invoices)', '../Dataset/apple_search_ads', '../Dataset/Atlassian', '../Dataset/Avenue_Logistics', '../Dataset/Aws', '../Dataset/AXLE_LOGISTICS', '../Dataset/Bacon_Work', '../Dataset/CDW_Direct', '../Dataset/CLEARFREIGHT_INC', '../Dataset/Cooley_LLP', '../Dataset/CSC', '../Dataset/Datadog', '../Dataset/DHL_eCommerce', '../Dataset/Electric_Al_Inc', '../Dataset/Employee_Benefits_Corporation', '../Dataset/Equifax_Information_SVCS_LLC', '../Dataset/esendex', '../Dataset/Facebook_Inc', '../Dataset/FedEx', '../Dataset/Freshworks_Inc_', '../Dataset/Github', '../Dataset/Glean_Analytics_Inc', '../Dataset/Goodwin_Procter_LLP', '../Dataset/google_llc', '../Dataset/Gowling_WLG_(Canada)_LLP', '../Dataset/Hubspot', '../Dataset/Lindenmeyr_Munroe', '../Dataset/LinkedIn_Corporation', '../Dataset/MainStreet_Work_Inc', '../Dataset/Maples_and_Calder_LLP', '../Dataset/Marcum_LLP', '../Dataset/Medline', '../Dataset/Microsoft_Corporation', '../Dataset/Perfect_Plastic_Printing_Corporation', '../Dataset/Plaid_Inc', '../Dataset/Randstad_Technologies_LLC', '../Dataset/RELX_Inc', '../Dataset/salesforce.com_inc', '../Dataset/SightSpan', '../Dataset/Slack_Technologies_Inc', '../Dataset/Smartly_Inc', '../Dataset/Total_Quality_Logistics', '../Dataset/Uber_Technologies_Inc', '../Dataset/ULINE', '../Dataset/WeWork_Companies_Inc_', '../Dataset/zoom']\n",
      "\n",
      "ADP_LLC vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 97/97 [00:00<00:00, 135.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Align_Technology_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 51/51 [00:00<00:00, 117.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALLIANCE_VANTAGE_LIMITED vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 40/40 [00:00<00:00, 120.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon_Business vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 279/279 [00:02<00:00, 116.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apple_Inc (invoices) vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 89/89 [00:00<00:00, 120.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apple_search_ads vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 80/80 [00:00<00:00, 112.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Atlassian vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 30/30 [00:00<00:00, 192.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avenue_Logistics vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 58/58 [00:00<00:00, 124.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aws vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 209/209 [00:04<00:00, 51.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AXLE_LOGISTICS vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:00<00:00, 141.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bacon_Work vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:00<00:00, 105.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CDW_Direct vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 122/122 [00:01<00:00, 97.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLEARFREIGHT_INC vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 51/51 [00:00<00:00, 82.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cooley_LLP vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:00<00:00, 152.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSC vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 53/53 [00:00<00:00, 103.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datadog vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 43/43 [00:00<00:00, 114.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DHL_eCommerce vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 89/89 [00:00<00:00, 157.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Electric_Al_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 97/97 [00:00<00:00, 134.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Employee_Benefits_Corporation vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 50/50 [00:00<00:00, 144.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equifax_Information_SVCS_LLC vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 62/62 [00:00<00:00, 109.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "esendex vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 28/28 [00:00<00:00, 130.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Facebook_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 17/17 [00:00<00:00, 131.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FedEx vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 112/112 [00:01<00:00, 98.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Freshworks_Inc_ vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 36/36 [00:00<00:00, 132.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Github vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 65/65 [00:00<00:00, 119.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glean_Analytics_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 68/68 [00:00<00:00, 120.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Goodwin_Procter_LLP vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 103/103 [00:00<00:00, 123.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "google_llc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 90/90 [00:00<00:00, 144.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gowling_WLG_(Canada)_LLP vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 95/95 [00:00<00:00, 121.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hubspot vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 96/96 [00:01<00:00, 85.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lindenmeyr_Munroe vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 62/62 [00:02<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinkedIn_Corporation vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 70/70 [00:00<00:00, 96.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MainStreet_Work_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 75/75 [00:00<00:00, 160.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maples_and_Calder_LLP vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 103/103 [00:00<00:00, 105.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Marcum_LLP vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 101/101 [00:00<00:00, 138.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Medline vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 68/68 [00:00<00:00, 123.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Microsoft_Corporation vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 96/96 [00:00<00:00, 118.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfect_Plastic_Printing_Corporation vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 55/55 [00:00<00:00, 105.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plaid_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:00<00:00, 149.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Randstad_Technologies_LLC vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:00<00:00, 138.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RELX_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 132/132 [00:01<00:00, 118.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "salesforce.com_inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 53/53 [00:00<00:00, 133.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SightSpan vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 40/40 [00:00<00:00, 122.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Slack_Technologies_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 51/51 [00:00<00:00, 142.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smartly_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:00<00:00, 110.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total_Quality_Logistics vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 100/100 [00:01<00:00, 70.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uber_Technologies_Inc vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 52/52 [00:00<00:00, 138.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ULINE vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 101/101 [00:00<00:00, 104.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WeWork_Companies_Inc_ vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 35/35 [00:00<00:00, 138.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "zoom vendor Processing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dirs: 100%|██████████| 36/36 [00:00<00:00, 134.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#path_of_dataset=input('Enter Path of Dataset to Begin: ')\n",
    "X,Y,map=prepare_all_dataset('../Dataset')#path_of_dataset)\n",
    "n_class=len(map)\n",
    "X=get_images_array(X)\n",
    "Y=np.asarray(Y)\n",
    "\n",
    "dump_load_map(map,0)\n",
    "#print(Y)\n",
    "\n",
    "Y=tf.keras.utils.to_categorical(\n",
    "    Y, num_classes=n_class, dtype='float32')\n",
    "\n",
    "\n",
    "class_weights=get_class_weights(Y)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8906122448979592,\n",
      " 1: 1.5585714285714285,\n",
      " 2: 2.182,\n",
      " 3: 0.2909333333333333,\n",
      " 4: 0.9091666666666667,\n",
      " 5: 0.8906122448979592,\n",
      " 6: 4.364,\n",
      " 7: 1.5048275862068965,\n",
      " 8: 0.2346236559139785,\n",
      " 9: 0.8728,\n",
      " 10: 0.8728,\n",
      " 11: 0.6234285714285714,\n",
      " 12: 1.6784615384615384,\n",
      " 13: 0.8728,\n",
      " 14: 1.6784615384615384,\n",
      " 15: 1.9836363636363636,\n",
      " 16: 0.9091666666666667,\n",
      " 17: 0.9091666666666667,\n",
      " 18: 1.7456,\n",
      " 19: 1.407741935483871,\n",
      " 20: 3.117142857142857,\n",
      " 21: 5.455,\n",
      " 22: 0.7273333333333334,\n",
      " 23: 2.4244444444444446,\n",
      " 24: 1.118974358974359,\n",
      " 25: 1.2835294117647058,\n",
      " 26: 0.8392307692307692,\n",
      " 27: 0.9697777777777777,\n",
      " 28: 0.9285106382978724,\n",
      " 29: 0.5594871794871795,\n",
      " 30: 1.407741935483871,\n",
      " 31: 0.9918181818181818,\n",
      " 32: 1.148421052631579,\n",
      " 33: 0.855686274509804,\n",
      " 34: 0.8728,\n",
      " 35: 1.3224242424242425,\n",
      " 36: 0.9285106382978724,\n",
      " 37: 1.3224242424242425,\n",
      " 38: 0.8728,\n",
      " 39: 0.8728,\n",
      " 40: 0.6713846153846154,\n",
      " 41: 1.7456,\n",
      " 42: 2.182,\n",
      " 43: 1.7456,\n",
      " 44: 0.8728,\n",
      " 45: 0.8728,\n",
      " 46: 1.6784615384615384,\n",
      " 47: 0.8728,\n",
      " 48: 2.5670588235294116,\n",
      " 49: 2.5670588235294116}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(class_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating Architecture of EffiicnetNetB0 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_Efficient_Net(image_shape=X[0].shape,output_shape=n_class):\n",
    "    if 'Efficient_net_custom.h5' in os.listdir(os.getcwd()):\n",
    "        print('Loaded Previous Model ')\n",
    "        model=tf.keras.models.load_model('Efficient_net_custom.h5')\n",
    "    else: \n",
    "        input_val=tf.keras.layers.Input(shape=image_shape)\n",
    "        model=EfficientNetB0(include_top=False,input_tensor=input_val,weights='imagenet')\n",
    "\n",
    "        for i in range(int(len(model.layers) * 0.75)):\n",
    "            model.layers[i].trainable = False\n",
    "\n",
    "        #model.trainable = False\n",
    "\n",
    "\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        top_dropout_rate = 0.8\n",
    "        x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "        #x=tf.keras.layers.Flatten()\n",
    "        output = tf.keras.layers.Dense(output_shape, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "        model=tf.keras.Model(inputs=input_val,outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "custom_model=Custom_Efficient_Net()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training The Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13/13 [==============================] - 41s 3s/step - loss: 1.2742 - accuracy: 0.7506 - val_loss: 3.3825 - val_accuracy: 0.2143\n",
      "Epoch 2/25\n",
      " 9/13 [===================>..........] - ETA: 10s - loss: 0.0791 - accuracy: 0.9835"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m )\n\u001b[1;32m----> 2\u001b[0m hist\u001b[39m=\u001b[39mcustom_model\u001b[39m.\u001b[39;49mfit(X_train,Y_train,validation_data\u001b[39m=\u001b[39;49m(X_test,Y_test),epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[callback],batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,class_weight\u001b[39m=\u001b[39;49mclass_weights)\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\FM-PC-LT-233\\anaconda3\\envs\\efficient_net_saving_fix\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss',mode='auto',restore_best_weights=True )\n",
    "hist=custom_model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=25,callbacks=[callback],batch_size=128,class_weight=class_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Saving Model and plotting the graphs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save('Efficient_net_custom.h5')\n",
    "plot_metrics_for_training(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yverify=custom_model.predict(X_test)\n",
    "Yverify=np.argmax(Yverify,axis=1).reshape(-1,1)\n",
    "Yverify_ground_truth=np.argmax(Y_test,axis=1).reshape(-1,1)\n",
    "op=classification_report(Yverify_ground_truth,Yverify)\n",
    "print(op)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Inference testing </h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D:\\Fuse_Work\\Glean_Experiments\\Dataset\\Medline\\01GH7C1RYM86F7JDQFJ1944V84.pdf\n",
    "loaded_model=tf.keras.models.load_model('Efficient_net_custom.h5')\n",
    "map=dump_load_map({},1)\n",
    "path_image=input('Enter PDF Path: ')\n",
    "test_img=inference_image_get(path_image)\n",
    "preds=loaded_model.predict(test_img.reshape(1,test_img.shape[0],test_img.shape[1],test_img.shape[2]))\n",
    "op=np.argmax(preds)\n",
    "print(list(preds[0])[op])\n",
    "if list(preds[0])[op]<=0.6:\n",
    "    print('This file belongs to none of the vendors ')\n",
    "else: \n",
    "    print(list(filter(lambda x: map[x] == op, map))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MISC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
